import os
import subprocess
from pathlib import Path

# ======= åŸºç¡€å‚æ•° =======
base_model = "runwayml/stable-diffusion-v1-5"
base_dir = Path("style_data")
output_root = Path("lora_outputs")

# ======= å¯è°ƒè¶…å‚æ•° =======
resolution = 512
lr = 5e-4
steps = 1200
batch_size = 1
accum_steps = 4
rank = 4
checkpoint_steps = 200  # æ¯200æ­¥ä¿å­˜ä¸€æ¬¡checkpointå¹¶éªŒè¯
validation_epochs = 50  # ç¦æ­¢é¢‘ç¹éªŒè¯ï¼Œä»…å½“ä¿å­˜checkpointæ—¶æ‰§è¡Œ

# ======= Wandb è®¾ç½® =======
os.environ["WANDB_PROJECT"] = "multi-style-lora"
os.environ["WANDB_LOG_MODEL"] = "true"
os.environ["WANDB_WATCH"] = "false"

# ======= è¦æ’é™¤çš„é£æ ¼ =======
exclude_styles = {"Flatillustration", "Oilpainting", "Sketch", "Watercolor"}

# ======= æ‰¹é‡è®­ç»ƒæ¯ä¸ªé£æ ¼ =======
for style_dir in base_dir.iterdir():
    if not style_dir.is_dir():
        continue
    if style_dir.name in exclude_styles:
        print(f"âš ï¸ è·³è¿‡æ’é™¤é£æ ¼: {style_dir.name}")
        continue

    # æ¯ä¸ªé£æ ¼å†…éƒ¨çš„å®é™…å›¾ç‰‡æ–‡ä»¶å¤¹ï¼Œä¾‹å¦‚ style_data/Cartoon/cartoon/
    inner_folders = [p for p in style_dir.iterdir() if p.is_dir()]
    if not inner_folders:
        print(f"âš ï¸ è·³è¿‡ {style_dir}ï¼šæœªæ‰¾åˆ°å­æ–‡ä»¶å¤¹")
        continue

    for inner in inner_folders:
        metadata_file = inner / "metadata.jsonl"
        if not metadata_file.exists():
            print(f"âš ï¸ è·³è¿‡ {inner}ï¼šæœªæ‰¾åˆ° metadata.jsonl")
            continue

        style_name = style_dir.name
        output_dir = output_root / style_name
        os.makedirs(output_dir, exist_ok=True)

        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒé£æ ¼: {style_name}")

        # æ„å»ºè®­ç»ƒå‘½ä»¤
        cmd = [
            "accelerate", "launch", "train_text_to_image_lora.py",
            f"--pretrained_model_name_or_path={base_model}",
            f"--train_data_dir={inner}",
            "--image_column=image",
            "--caption_column=text",
            f"--validation_prompt=A photo in {style_name} style.",
            "--num_validation_images=4",
            f"--resolution={resolution}",
            f"--train_batch_size={batch_size}",
            f"--gradient_accumulation_steps={accum_steps}",
            f"--learning_rate={lr}",
            f"--max_train_steps={steps}",
            f"--checkpointing_steps={checkpoint_steps}",
            f"--rank={rank}",
            "--mixed_precision=fp16",
            "--lr_scheduler=constant",
            f"--validation_epochs={validation_epochs}",
            "--report_to=wandb",
            f"--output_dir={output_dir}"
        ]

        print(" ".join(cmd))
        subprocess.run(cmd)

print("\nâœ… æ‰€æœ‰é£æ ¼è®­ç»ƒå®Œæˆï¼")